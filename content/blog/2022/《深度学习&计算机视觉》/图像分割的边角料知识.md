---
title: "图像分割的边角料"
date: 2022-08-21T18:18:05+08:00
lastmod: 2022-08-21T09:19:06+08:00
draft: false
featured_image: "https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img_title.jpg"
description: "主要介绍图像分割的上采样和指标计算"
tags:
- Deep_learning
categories:
- 深度学习
- 图像分割
series:
- 《深度学习》学习笔记
comment : true
---

### 图像分割中的上采样方法

#### 反最大池化的方法

在下采样中，我们通常采用最大池化的方法来进行。那么对应在上采样中，反最大池化的方法其实就是记住最大池化时得到像素在原图中的位置，将其他位置填充为0。如图所示：

![](https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img64.jpg)

*最早的SegNet所使用的上采样就是这种方式！*

#### 转置卷积

第二种方法就是`转置卷积`,这种方法和前面的`反最大池化方法`的最大区别就是转置卷积的参数是可以用于学习训练的，它不是一个固定的策略！

![](https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img65.jpg)

这个图可能看的不是很准确，想看动图的可以访问[PyTorch官方给出的动图](https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md)

> 以3$\times$3的卷积核将2$\times$2变为4$\times$4的图像为例（没有填充，没有步幅）：
>
> 1.第一步就是要将2$\times$2的图像使用零padding成为一个6$\times$6（4+2*1得到）的图像
>
> 2.对该填充后的图像做3$\times$3的卷积，得到输出图像

*在深度学习的论文中，出现反卷积/跨步卷积/上卷积其实指的就是这种转置卷积。*

放一张一维的图用于理解：

![](https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img66.jpg)

### 指标计算

#### 基本指标

在图像分割中的基本指标通常包括`混淆矩阵`、`Recall`、`Precision`、`MIOU`等指标。

> 二分类中：
>
> TP：原来是正样本，正确预测为了正样本
>
> FN：原来为正样本，错误预测为了负样本
>
> FP：原来为负样本，错误预测为了正样本
>
> TN：原来是负样本，正确预测为了负样本
>
> Recall：正确预测为正样本的个数/原来正样本的个数
>
> recall = TP/（TP+FN）
>
> Precision：正确的预测为了正样本个数/预测为正样本的个数
>
> precision = TP /（TP+FP）
>
> IOU = 交集/并集
>
> MIOU：平均的IOU
>
> 多分类时：
>
> $miou = \frac{1}{k + 1}\sum_{i=0}^k TP /(TP + FP + FN)$



#### 实操

```python
'''
    混淆矩阵
    Recall、Precision、MIOU计算
'''
import numpy as np
from sklearn.metrics import confusion_matrix
import cv2

# 输入必须为灰度图
# labels为你的像素值的类别
from utils import keep_image_size_open


def get_miou_recall_precision(label_image, pred_image, labels):
    label = label_image.reshape(-1)
    pred = pred_image.reshape(-1)
    out = confusion_matrix(label, pred, labels=labels)
    # print(out)
    # TP = out[0][0]
    # FN = out[0][1] + out[0][2]
    # FP = out[1][0] + out[2][0]
    # TN = out[1][1] + out[1][2] + out[2][1] + out[2][2]
    # print(TP / (TP + FP + FN))
    r, l = out.shape
    iou_temp = 0
    recall = {}
    precision = {}
    for i in range(r):
        TP = out[i][i]
        temp = np.concatenate((out[0:i, :], out[i + 1:, :]), axis=0)
        sum_one = np.sum(temp, axis=0)
        FP = sum_one[i]
        temp2 = np.concatenate((out[:, 0:i], out[:, i + 1:]), axis=1)
        FN = np.sum(temp2, axis=1)[i]
        TN = temp2.reshape(-1).sum() - FN
        iou_temp += (TP / (TP + FP + FN))
        recall[i] = TP / (TP + FN)
        precision[i] = TP / (TP + FP)
    MIOU = iou_temp / len(labels)
    return MIOU, recall, precision


if __name__ == '__main__':
    from PIL import Image
    label = keep_image_size_open(r'D:\pythonSpace\teach_demo\pytorch-unet\data\SegmentationClass\000799.png')
    pred = Image.open(r'D:\pythonSpace\teach_demo\pytorch-unet\result\result.png')
    l, p = np.array(label).astype(int), np.array(pred).astype(int)
    print(get_miou_recall_precision(l, p, [0, 1, 2]))

```

