---
title: "从零实现深度学习推理框架"
date: 2023-08-12T18:18:05+08:00
lastmod: 2023-08-13T09:19:06+08:00
draft: false
featured_image: "https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA_title.jpg"
description: "从零实现一个深度学习推理框架！"
tags:
- 深度学习推理框架
categories:
- HPC
series:
- 深度学习框架
comment : true
---


## 从零自制深度学习推理框架

> 什么是推理框架

深度学习推理框架用于对**已经训练完成的神经网络模型文件进行加载**，并根据模型文件中的**网络结构和权重参数**对输入图像进行预测。换句话说，深度学习推理框架就是将深度学习训练框架`Pytorch`和`TensorFlow`中训练完成的模型，移植到中心侧和端侧并且在运行时**高效执行**。

另外，与深度学习训练框架不同的是，推理框架没有梯度后向传播的过程，因为**在推理阶段模型的权重已经固定，不需要利用后向传播技术进一步进行调整**。

推理框架流程：

![](https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img90.jpg)

> 技术全景概述

开源项目`KuiperInfer`可以分为以下的几个模块：

1. `Operator`:深度学习计算图中的计算节点，包含以下的几个部分：
   * **存储输入输出的张量**，用于存放深度学习中各层的输入输出。比如对于一个`Convolution`层，需要一部分空间来保存计算的输入和输出。
   * **计算节点的类型和名称**，计算节点类型可以有`Convolution`, `Relu`, `Maxpooling`等，计算节点的**名称是唯一的**，用来区分任意一个节点，可以是`Convolution_1`, `Convolution_2`等。
   * **计算节点的参数信息**，例如卷积中的步长、卷积核的大小等。
   * **计算节点的权重信息**，例如卷积节点中的`weight`, `bias`权重。
2. `Graph`: 有多个`Operator`串联得到的有向无环图，规定了各个计算节点（`Operator`）执行的流程和顺序。
3. `Layer`：计算节点中运算的具体执行者，`Layer`类先读取输入张量中的数据，然后对输入张量进行计算，得到的结果存放到计算节点的输出张量中，**当然，不同的算子中`Layer`的计算过程会不一致**。
4. `Tensor`: 用于存放**多维数据**的数据结构，方便数据在计算节点之间传递，同时该结构也封装矩阵乘、点积等与矩阵相关的基本操作。

以下的图示是对如上的模块的总结，每个节点都从输入张量`input_data`中读取数据，并调用该节点对应的`Layer`计算对应的结果，最后再将结果放入到`output_data`中。整个计算图第一个节点的输入也是计算图全局的输入，同时，最后一个节点的输出也是整个计算图的全局输出。

![](https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img91.jpg)

### 第一课：环境准备&测试准备

#### Docker环境准备

1. 首先需要下载Docker，以及了解其使用，这些需要自行了解。

2. 拉取Docker镜像：

```shell
sudo docker pull registry.cn-hangzhou.aliyuncs.com/hellofss/kuiperinfer:datawhale
```

3. 创建并运行一个容器

```shell
sudo docker run -it registry.cn-hangzhou.aliyuncs.com/hellofss/kuiperinfer:datawhale /bin/bash
```

4. 在容器中输入`ifconfig`命令查看`ip`地址。（注意，这里使用的必须是172开头的地址）

5. 在宿主机使用ssh（容器内已经存在开发所需要的环境和openssh）连接容器，这里的**用户名固定是`me`, `ip`地址是上方`ipconfig`输出中的`inet`, 登录密码是1.**

```shell
ssh me@172.17.0.2
```

#### VSCode连接容器

1. 在 VSCode 中，连接容器是一件很简单的事情，首先你需要安装 Docker 插件，点击左侧的扩展栏（或是按下 ctrl+shift+X），键入 Docker，随后选择安装。

   在成功进入容器之前，我们还需要再安装几个小插件，我们接着搜索 `Dev container` 以及 `Remote Development` 插件，都安装第一个即可。

2. 接下来，你需要右键之前启动的容器 `registry.cn-hangzhou.aliyuncs.com/hellofss/kuiperinfer:datawhale`，选择 **附加 Visual Studio Code** 进入 Docker 环境。

   在进入 Docker 环境后，我们还需要手动再次 clone 课程代码，你可以执行 `ctrl + J` 调出控制台终端，在终端中输入：

   ```bash
   cd /home 
   git clone https://github.com/zjhellofss/kuiperdatawhale.git
   ```

   然后在左上角选择**文件 —— 打开文件夹 —— /home/kuiperdatawhale —— 确定**即可进入课程主界面。

3. 进入 Docker 环境后的 VSCode 拥有独立的插件环境，所以我们需要重新安装有关插件：

   你需要在此时的主界面找到扩展，且根据安装 Docker 插件的步骤自行搜索完成以下几款插件的安装：

   CMake 相关插件的安装。

   C++ 相关插件的安装。

4. 首先，你需要点击工具图表，选择 `GCC 9.4.0 x86_64-linux-gnu` 版本的编译工具，确保编译工具一致。接下来让我们尝试编译运行主程序，只需要在 ▶ 键右侧选择对应的编译目标（比如图中我选择了 `kuiper_datawhale_course1`），再点击▶ 按钮 即可开始编译运行。

![](https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img92.jpg)

#### 用 Clion 连接容器

容器在运行的时候已经打开了一个`ssh`服务，所以我们只需要用`Clion`进行连接即可，在连接成功之后项目的代码就可以直接在容器中进行编译运行。

1. 在`Clion`的左上角点击`File-->Open`，打开项目所在的文件夹，也就是刚才的`~/code/kuiperdatawhale/kuiperdatawhale`文件夹。

2. 在**容器内**输入`ifconfig`, 注意是**容器内，不是你宿主机上**！

```shell
eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 172.17.0.4  netmask 255.255.0.0  broadcast 172.17.255.255
        ether 02:42:ac:11:00:04  txqueuelen 0  (Ethernet)
        RX packets 55  bytes 8479 (8.4 KB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 0  bytes 0 (0.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
```

3. 在确保容器已经在运行后，再在`Clion`的`Toolchain`设置为容器内的编程环境

   * 点击`Clion`软件左上角的`File->Settings`, 并在左侧对应位置找到`Toolchains`

   - 在3处将host修改为容器中输入`ifconfig`命令得到的`ip`地址，**并将`username`设置为`me`, 登录方式为密码登录，密码为1**.

   - 所有信息填好之后点击`Test Connection`. 如果连接成功，则会显示`Connected Successfully`,  如果此处连接失败，可以尝试替换映射端口或自行查阅资料解决。![](https://i.imgur.com/6tJcIbQ.png)

   - 随后将`datawhale`一栏拖动到最上方（鼠标左键拖动），表示**软件默认使用容器内的编译工具链**。

4. 现在编程环境已经配置到了`Docker`容器中，随后点击菜单栏的`Helps->Find actions`, 再输入`Reload Cmake Project` 对项目进行重新加载，包括如果你之后修改了`Cmake`文件，最好都用这个命令重新加载下项目。

   - **如果发现头文件报错或者不能智能提示**，可以在`Find actions`中输入`resync with remote hosts`来同步远程的头文件。

5. 随后就可以选择`course1`并点击三角形按钮对项目代码进行执行。
   ![](https://i.imgur.com/eRHKML8.png)

   如果配置成功，程序会出现如下的运行结果，出现`Failed`这是因为本节课作业需要完成一定的代码，若作业都正确完成，`Failed`标签就会在运行结果中消失。

```shell
[==========] Running 7 tests from 1 test suite.
[----------] Global test environment set-up.
[----------] 7 tests from test_arma
[ RUN      ] test_arma.Axby
/tmp/tmp.dvfnZylz2q/course1/test/axby.cpp:32: Failure
Expected equality of these values:
  approx_equal(y, answer, "absdiff", 1e-5f)
    Which is: false
  true
[  FAILED  ] test_arma.Axby (0 ms)
[ RUN      ] test_arma.e_power_minus
```

#### 如何进行单元测试

搭建好了环境，我们来写一些单元测试看看运行情况。同时，在这个过程中，我们也试着去写项目的单元测试。单元测试框架使用了`Google`的`Google Test`, 该框架已经在`Docker`镜像中提供。 我们以矩阵库`armadillo`的计算接口作为我们的测试目标，在测试的过程中也去熟悉这个矩阵库的基本用法，以下是`armadillo`矩阵库的文档地址，以供我们在学习的过程中查阅：[armadillo documentation](https://arma.sourceforge.net/docs.html). 

Example:

1. `test_add`函数用来测试`armadillo`的矩阵加法接口

   ```cpp
   #include <armadillo>
   #include <glog/logging.h>
   #include <gtest/gtest.h>
   
   TEST(test_arma, add) {
     using namespace arma;
     fmat in_matrix1 = "1,2,3;"
                       "4,5,6;"
                       "7,8,9";
   
     fmat in_matrix2 = "1,2,3;"
                       "4,5,6;"
                       "7,8,9";
   
     const fmat &out_matrix1 = "2,4,6;"
                               "8,10,12;"
                               "14,16,18";
   
     const fmat &out_matrix2 = in_matrix1 + in_matrix2;
     ASSERT_EQ(approx_equal(out_matrix1, out_matrix2, "absdiff", 1e-5), true);
   }
   ```

2. `test_sub`函数用来测试`armadillo`的矩阵减法接口

   ```cpp
   #include <armadillo>
   #include <glog/logging.h>
   #include <gtest/gtest.h>
   
   TEST(test_arma, sub) {
     using namespace arma;
     fmat in_matrix1 = "1,2,3;"
                       "4,5,6;"
                       "7,8,9";
   
     fmat in_matrix2 = "1,2,3;"
                       "4,5,6;"
                       "7,8,9";
   
     const fmat &out_matrix1 = "0,0,0;"
                               "0,0,0;"
                               "0,0,0;";
   
     const fmat &out_matrix2 = in_matrix1 - in_matrix2;
     ASSERT_EQ(approx_equal(out_matrix1, out_matrix2, "absdiff", 1e-5), true);
   }
   ```

所有的测试代码都放在了`test`文件夹下，`Cmake`构建系统会去自动读取该文件夹下的单元测试文件，**如果新添加了`.cpp`文件或者新的单元测试函数**，需要使用`Reload Cmake Project`重新进行载入。

### 第二课：张量的设计与实现

对于一个张量类而言，数据将被设计成依次摆放的三维格式，分别是`channels`(通道数),  `rows`(行数)，`cols`(列数)。一个张量类主要由以下部分组成：

1. 数据本身存储在该类的数据空间中，数据可包括双精度(`double`)、单精度(`float`)或整型(`int`)。

2. 为了处理多维张量数据，需要使用`shape`变量来存储张量的维度信息。例如，对于一个维度为`3`，长和宽均为`224`的张量，其维度信息可以表示为`(3, 224, 224)`。

3. 张量类中定义了多个类方法，如返回张量的宽度、高度、填充数据和张量变形 (`reshape`)等操作。

#### 张量类的设计

从头设计一个张量类具有较大的编码难度，因此，在本项目中，我们选择在`arma::fcube`（三维矩阵）的基础上进行开发。

三维的`arma::fcube`是由多个二维矩阵`matrix`（即上一节课中介绍的`arma::fmat`）沿通道维度叠加得到。在此基础上，我们的张量类将在叠加而成的三维矩阵`arma::fcube`的基础上提供扩充和封装，以使其更适用于我们的推理框架项目。

对于这样的一个Tensor类，我们主要需要做以下的两个工作：

1. 提供对外的接口，对外接口由`Tensor`类在`fcube`类的基础上进行提供，以供用户更好地访问多维数据。
2. 封装矩阵相关的计算功能，这样一来不仅有更友好的数据访问和使用方式，也能有高效的矩阵算法实现。

> `arma::fmat` 与 `arma::fcube` 的区别。

`arma::fcube` 是`arma::fmat`沿通道维度进行叠加而成。

#### 数据的摆放顺序

其实就是操作系统中提到两个概念为`行优先`和`列优先`，对应到这里就是`行主序`和`列主序`。**在`armadillo`中默认的顺序就是列主序的，而Pytorch张量默认顺序是行主序的，所以我们在程序中需要进行一定适应和调整。**